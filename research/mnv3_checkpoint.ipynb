{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77add542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Text, List, Dict, Tuple, Callable\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ce9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from official.vision.beta.modeling import backbones\n",
    "from official.vision.beta.modeling import classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6b81244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from research.mobilenet.mobilenet_v3 import mobilenet_v3_large\n",
    "from research.mobilenet.mobilenet_trainer import _get_dataset_config, get_dataset\n",
    "\n",
    "from research.mobilenet.configs import archs\n",
    "MobileNetV3LargeConfig = archs.MobileNetV3LargeConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b643fd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_moving_average(ma_terms: List[Text]) -> List[Text]:\n",
    "  \"\"\"\n",
    "    MobilenetV2/Conv/BatchNorm/moving_variance\n",
    "    MobilenetV2/Conv/BatchNorm/moving_variance/ExponentialMovingAverage\n",
    "    MobilenetV3/expanded_conv_9/project/BatchNorm/moving_mean/ExponentialMovingAverage\n",
    "  Args:\n",
    "    ma_terms: a list of names related to moving average\n",
    "\n",
    "  Returns:\n",
    "    a list of names after de-duplicating\n",
    "  \"\"\"\n",
    "  output_list = list()\n",
    "  base_name_set = set()\n",
    "  replace_flag = False\n",
    "  for item in ma_terms:\n",
    "    base_name = item\n",
    "    item_split = item.split('/')\n",
    "    if 'moving_' in item_split[-2]:\n",
    "      base_name = '/'.join(item_split[0:-1])\n",
    "      replace_flag = True\n",
    "\n",
    "    if base_name in base_name_set:\n",
    "      if replace_flag:\n",
    "        t_index = output_list.index(base_name)\n",
    "        output_list[t_index] = item\n",
    "    else:\n",
    "      output_list.append(item)\n",
    "      base_name_set.add(base_name)\n",
    "\n",
    "    replace_flag = False\n",
    "\n",
    "  return output_list\n",
    "\n",
    "\n",
    "def _load_weights_from_ckpt(checkpoint_path: Text,\n",
    "                            include_filters: List[Text],\n",
    "                            exclude_filters: List[Text]\n",
    "                            ) -> Dict[Text, tf.Tensor]:\n",
    "  \"\"\"Load all the weights stored in the checkpoint as {var_name: var_value}\n",
    "\n",
    "  Args:\n",
    "    checkpoint_path: path to the checkpoint file xxxxx.ckpt\n",
    "    include_filters: list of keywords that determine which var_names should be\n",
    "    kept in the output list\n",
    "    exclude_filters: list of keywords that determine which var_names should be\n",
    "    excluded from the output list\n",
    "\n",
    "  Returns:\n",
    "    A dictionary of {var_name: tensor values}\n",
    "  \"\"\"\n",
    "  reader = tf.compat.v1.train.NewCheckpointReader(checkpoint_path)\n",
    "  var_shape_map = reader.get_variable_to_shape_map()\n",
    "  ma_terms = list()\n",
    "\n",
    "  var_value_map = {}\n",
    "  for item in var_shape_map:\n",
    "    include_check = True\n",
    "    if include_filters:\n",
    "      include_check = any([to_check in item\n",
    "                           for to_check in include_filters])\n",
    "    exclude_check = True\n",
    "    if exclude_filters:\n",
    "      exclude_check = all([to_check not in item\n",
    "                           for to_check in exclude_filters])\n",
    "\n",
    "    if exclude_check and 'moving_' in item:\n",
    "      ma_terms.append(item)\n",
    "    elif include_check and exclude_check:\n",
    "      var_value_map[item] = reader.get_tensor(item)\n",
    "\n",
    "  processed_ma_terms = _process_moving_average(ma_terms)\n",
    "  for p_item in processed_ma_terms:\n",
    "    var_value_map[p_item] = reader.get_tensor(p_item)\n",
    "  \n",
    "  return var_value_map\n",
    "\n",
    "\n",
    "def _decouple_layer_name(var_value_map: Dict[Text, tf.Tensor],\n",
    "                         use_mv_average: bool = True\n",
    "                         ) -> List[Tuple[Text, Text, tf.Tensor]]:\n",
    "  \"\"\"Sort the names of the weights by the layer they correspond to. The example\n",
    "  names of the weightes:\n",
    "    MobilenetV1/Conv2d_0/weights\n",
    "    MobilenetV1/Conv2d_9_pointwise/weights\n",
    "    MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta\n",
    "    MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta/ExponentialMovingAverage\n",
    "\n",
    "    Model_Name/Layer_Name/Component_Name[/Extra]\n",
    "\n",
    "  Args:\n",
    "    var_value_map: a dictionary of {var_name: tensor values}\n",
    "    use_mv_average: whether `ExponentialMovingAverage` should be used. If this\n",
    "    is true, the `ExponentialMovingAverage` related weightes should be included\n",
    "    in  `var_value_map`.\n",
    "\n",
    "  Returns:\n",
    "    A list of (layer_num, layer_name, layer_component, weight_value)\n",
    "  \"\"\"\n",
    "  layer_list = []\n",
    "  for weight_name, weight_value in var_value_map.items():\n",
    "    weight_name_split = weight_name.split('/')\n",
    "    if use_mv_average and 'ExponentialMovingAverage' in weight_name:\n",
    "      # MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta/ExponentialMovingAverage\n",
    "      layer_name = '/'.join(weight_name_split[1:-2])\n",
    "      layer_component = '/'.join(weight_name_split[-2:-1])\n",
    "    else:\n",
    "      # MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta\n",
    "      layer_name = '/'.join(weight_name_split[1:-1])\n",
    "      layer_component = '/'.join(weight_name_split[-1:])\n",
    "\n",
    "    layer_list.append(\n",
    "      (layer_name, layer_component, weight_value))\n",
    "\n",
    "  return layer_list\n",
    "\n",
    "\n",
    "def _layer_weights_list_to_map(\n",
    "    layer_ordered_list: List[Tuple[Text, Text, tf.Tensor]]\n",
    ") -> Dict[Text, List[tf.Tensor]]:\n",
    "  \"\"\"Organize same layer with multiple components into group.\n",
    "  For example: BatchNorm has 'gamma', 'beta', 'moving_mean', 'moving_variance'\n",
    "\n",
    "  Args:\n",
    "    layer_ordered_list: A list of (layer_num, layer_name,\n",
    "    layer_component, weight_value)\n",
    "\n",
    "  Returns:\n",
    "    A dictionary of {layer_name: layer_weights}\n",
    "  \"\"\"\n",
    "\n",
    "  # define the vars order in Keras layer\n",
    "  batchnorm_order = ['gamma', 'beta', 'moving_mean', 'moving_variance']\n",
    "  dense_cnn_order = ['weights', 'biases']\n",
    "  depthwise_order = ['depthwise_weights', 'biases']\n",
    "\n",
    "  # Organize same layer with multiple components into group\n",
    "  keras_weights = defaultdict(list)\n",
    "\n",
    "  for (layer_name, layer_component, weight) in layer_ordered_list:\n",
    "    keras_weights[layer_name].append((layer_component, weight))\n",
    "\n",
    "  # Sort within each group. The ordering should be\n",
    "  ordered_layer_weights = {}\n",
    "\n",
    "  for group_name, group in keras_weights.items():\n",
    "    # format of group: [(layer_component, weight)]\n",
    "    if len(group) == 1:\n",
    "      order_weight_group = [group[0][1]]\n",
    "    else:\n",
    "      group_len = len(group)\n",
    "      order_weight_group = [0] * group_len\n",
    "\n",
    "      if group_len == 2:\n",
    "        target_order = dense_cnn_order\n",
    "        if 'depthwise' in group_name:\n",
    "          target_order = depthwise_order\n",
    "      elif group_len == 4:\n",
    "        target_order = batchnorm_order\n",
    "      else:\n",
    "        raise ValueError(\n",
    "          'The number of components {} in a layer is not supported for {}'.format(\n",
    "            group_len, group_name))\n",
    "\n",
    "      for item_name, item_value in group:\n",
    "        index = target_order.index(item_name)\n",
    "        order_weight_group[index] = item_value\n",
    "\n",
    "    ordered_layer_weights[group_name] = order_weight_group\n",
    "\n",
    "  return ordered_layer_weights\n",
    "\n",
    "\n",
    "def generate_layer_weights_map(checkpoint_path: Text,\n",
    "                               include_filters: List[Text],\n",
    "                               exclude_filters: List[Text],\n",
    "                               use_mv_average: bool = True\n",
    "                               ) -> Dict[Text, List[tf.Tensor]]:\n",
    "  \"\"\"Generate a dictionary of {layer_name: layer_weights} from checkpoint.\n",
    "\n",
    "  Args:\n",
    "    checkpoint_path: path to the checkpoint file xxxxx.ckpt\n",
    "    include_filters: list of keywords that determine which var_names should be\n",
    "    kept in the output list\n",
    "    exclude_filters: list of keywords that determine which var_names should be\n",
    "    excluded from the output list\n",
    "    use_mv_average: whether `ExponentialMovingAverage` should be used. If this\n",
    "    is true, the `ExponentialMovingAverage` related weightes should be included\n",
    "    in  `var_value_map`.\n",
    "\n",
    "  Returns:\n",
    "    A dictionary of {layer_name: layer_weights}\n",
    "  \"\"\"\n",
    "  var_value_map = _load_weights_from_ckpt(\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    include_filters=include_filters,\n",
    "    exclude_filters=exclude_filters)\n",
    "\n",
    "  layer_ordered_list = _decouple_layer_name(\n",
    "    var_value_map=var_value_map,\n",
    "    use_mv_average=use_mv_average)\n",
    "\n",
    "  ordered_layer_weights = _layer_weights_list_to_map(\n",
    "    layer_ordered_list=layer_ordered_list)\n",
    "\n",
    "  return ordered_layer_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3769c72",
   "metadata": {},
   "source": [
    "## Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "20ea7890",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_checkpoint = '/home/jupyter/v3-large_224_1.0_float/pristine/model.ckpt-540000'\n",
    "reader = tf.compat.v1.train.NewCheckpointReader(source_checkpoint)\n",
    "var_shape_map = reader.get_variable_to_shape_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c5809a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_value_map = _load_weights_from_ckpt(source_checkpoint, \n",
    "                                 ['ExponentialMovingAverage'], \n",
    "                                 ['RMSProp', 'global_step', 'loss', 'Momentum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c07639ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_ordered_list = _decouple_layer_name(var_value_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c9c074fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_keras_weights = _layer_weights_list_to_map(layer_ordered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bf31b568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Conv', [(3, 3, 3, 16)]),\n",
       " ('Conv/BatchNorm', [(16,), (16,), (16,), (16,)]),\n",
       " ('Conv_1', [(1, 1, 160, 960)]),\n",
       " ('Conv_1/BatchNorm', [(960,), (960,), (960,), (960,)]),\n",
       " ('Conv_2', [(1, 1, 960, 1280), (1280,)]),\n",
       " ('Logits/Conv2d_1c_1x1', [(1, 1, 1280, 1001), (1001,)]),\n",
       " ('expanded_conv/depthwise', [(3, 3, 16, 1)]),\n",
       " ('expanded_conv/depthwise/BatchNorm', [(16,), (16,), (16,), (16,)]),\n",
       " ('expanded_conv/project', [(1, 1, 16, 16)]),\n",
       " ('expanded_conv/project/BatchNorm', [(16,), (16,), (16,), (16,)]),\n",
       " ('expanded_conv_1/depthwise', [(3, 3, 64, 1)]),\n",
       " ('expanded_conv_1/depthwise/BatchNorm', [(64,), (64,), (64,), (64,)]),\n",
       " ('expanded_conv_1/expand', [(1, 1, 16, 64)]),\n",
       " ('expanded_conv_1/expand/BatchNorm', [(64,), (64,), (64,), (64,)]),\n",
       " ('expanded_conv_1/project', [(1, 1, 64, 24)]),\n",
       " ('expanded_conv_1/project/BatchNorm', [(24,), (24,), (24,), (24,)]),\n",
       " ('expanded_conv_10/depthwise', [(3, 3, 480, 1)]),\n",
       " ('expanded_conv_10/depthwise/BatchNorm', [(480,), (480,), (480,), (480,)]),\n",
       " ('expanded_conv_10/expand', [(1, 1, 80, 480)]),\n",
       " ('expanded_conv_10/expand/BatchNorm', [(480,), (480,), (480,), (480,)]),\n",
       " ('expanded_conv_10/project', [(1, 1, 480, 112)]),\n",
       " ('expanded_conv_10/project/BatchNorm', [(112,), (112,), (112,), (112,)]),\n",
       " ('expanded_conv_10/squeeze_excite/Conv', [(1, 1, 480, 120), (120,)]),\n",
       " ('expanded_conv_10/squeeze_excite/Conv_1', [(1, 1, 120, 480), (480,)]),\n",
       " ('expanded_conv_11/depthwise', [(3, 3, 672, 1)]),\n",
       " ('expanded_conv_11/depthwise/BatchNorm', [(672,), (672,), (672,), (672,)]),\n",
       " ('expanded_conv_11/expand', [(1, 1, 112, 672)]),\n",
       " ('expanded_conv_11/expand/BatchNorm', [(672,), (672,), (672,), (672,)]),\n",
       " ('expanded_conv_11/project', [(1, 1, 672, 112)]),\n",
       " ('expanded_conv_11/project/BatchNorm', [(112,), (112,), (112,), (112,)]),\n",
       " ('expanded_conv_11/squeeze_excite/Conv', [(1, 1, 672, 168), (168,)]),\n",
       " ('expanded_conv_11/squeeze_excite/Conv_1', [(1, 1, 168, 672), (672,)]),\n",
       " ('expanded_conv_12/depthwise', [(5, 5, 672, 1)]),\n",
       " ('expanded_conv_12/depthwise/BatchNorm', [(672,), (672,), (672,), (672,)]),\n",
       " ('expanded_conv_12/expand', [(1, 1, 112, 672)]),\n",
       " ('expanded_conv_12/expand/BatchNorm', [(672,), (672,), (672,), (672,)]),\n",
       " ('expanded_conv_12/project', [(1, 1, 672, 160)]),\n",
       " ('expanded_conv_12/project/BatchNorm', [(160,), (160,), (160,), (160,)]),\n",
       " ('expanded_conv_12/squeeze_excite/Conv', [(1, 1, 672, 168), (168,)]),\n",
       " ('expanded_conv_12/squeeze_excite/Conv_1', [(1, 1, 168, 672), (672,)]),\n",
       " ('expanded_conv_13/depthwise', [(5, 5, 960, 1)]),\n",
       " ('expanded_conv_13/depthwise/BatchNorm', [(960,), (960,), (960,), (960,)]),\n",
       " ('expanded_conv_13/expand', [(1, 1, 160, 960)]),\n",
       " ('expanded_conv_13/expand/BatchNorm', [(960,), (960,), (960,), (960,)]),\n",
       " ('expanded_conv_13/project', [(1, 1, 960, 160)]),\n",
       " ('expanded_conv_13/project/BatchNorm', [(160,), (160,), (160,), (160,)]),\n",
       " ('expanded_conv_13/squeeze_excite/Conv', [(1, 1, 960, 240), (240,)]),\n",
       " ('expanded_conv_13/squeeze_excite/Conv_1', [(1, 1, 240, 960), (960,)]),\n",
       " ('expanded_conv_14/depthwise', [(5, 5, 960, 1)]),\n",
       " ('expanded_conv_14/depthwise/BatchNorm', [(960,), (960,), (960,), (960,)]),\n",
       " ('expanded_conv_14/expand', [(1, 1, 160, 960)]),\n",
       " ('expanded_conv_14/expand/BatchNorm', [(960,), (960,), (960,), (960,)]),\n",
       " ('expanded_conv_14/project', [(1, 1, 960, 160)]),\n",
       " ('expanded_conv_14/project/BatchNorm', [(160,), (160,), (160,), (160,)]),\n",
       " ('expanded_conv_14/squeeze_excite/Conv', [(1, 1, 960, 240), (240,)]),\n",
       " ('expanded_conv_14/squeeze_excite/Conv_1', [(1, 1, 240, 960), (960,)]),\n",
       " ('expanded_conv_2/depthwise', [(3, 3, 72, 1)]),\n",
       " ('expanded_conv_2/depthwise/BatchNorm', [(72,), (72,), (72,), (72,)]),\n",
       " ('expanded_conv_2/expand', [(1, 1, 24, 72)]),\n",
       " ('expanded_conv_2/expand/BatchNorm', [(72,), (72,), (72,), (72,)]),\n",
       " ('expanded_conv_2/project', [(1, 1, 72, 24)]),\n",
       " ('expanded_conv_2/project/BatchNorm', [(24,), (24,), (24,), (24,)]),\n",
       " ('expanded_conv_3/depthwise', [(5, 5, 72, 1)]),\n",
       " ('expanded_conv_3/depthwise/BatchNorm', [(72,), (72,), (72,), (72,)]),\n",
       " ('expanded_conv_3/expand', [(1, 1, 24, 72)]),\n",
       " ('expanded_conv_3/expand/BatchNorm', [(72,), (72,), (72,), (72,)]),\n",
       " ('expanded_conv_3/project', [(1, 1, 72, 40)]),\n",
       " ('expanded_conv_3/project/BatchNorm', [(40,), (40,), (40,), (40,)]),\n",
       " ('expanded_conv_3/squeeze_excite/Conv', [(1, 1, 72, 24), (24,)]),\n",
       " ('expanded_conv_3/squeeze_excite/Conv_1', [(1, 1, 24, 72), (72,)]),\n",
       " ('expanded_conv_4/depthwise', [(5, 5, 120, 1)]),\n",
       " ('expanded_conv_4/depthwise/BatchNorm', [(120,), (120,), (120,), (120,)]),\n",
       " ('expanded_conv_4/expand', [(1, 1, 40, 120)]),\n",
       " ('expanded_conv_4/expand/BatchNorm', [(120,), (120,), (120,), (120,)]),\n",
       " ('expanded_conv_4/project', [(1, 1, 120, 40)]),\n",
       " ('expanded_conv_4/project/BatchNorm', [(40,), (40,), (40,), (40,)]),\n",
       " ('expanded_conv_4/squeeze_excite/Conv', [(1, 1, 120, 32), (32,)]),\n",
       " ('expanded_conv_4/squeeze_excite/Conv_1', [(1, 1, 32, 120), (120,)]),\n",
       " ('expanded_conv_5/depthwise', [(5, 5, 120, 1)]),\n",
       " ('expanded_conv_5/depthwise/BatchNorm', [(120,), (120,), (120,), (120,)]),\n",
       " ('expanded_conv_5/expand', [(1, 1, 40, 120)]),\n",
       " ('expanded_conv_5/expand/BatchNorm', [(120,), (120,), (120,), (120,)]),\n",
       " ('expanded_conv_5/project', [(1, 1, 120, 40)]),\n",
       " ('expanded_conv_5/project/BatchNorm', [(40,), (40,), (40,), (40,)]),\n",
       " ('expanded_conv_5/squeeze_excite/Conv', [(1, 1, 120, 32), (32,)]),\n",
       " ('expanded_conv_5/squeeze_excite/Conv_1', [(1, 1, 32, 120), (120,)]),\n",
       " ('expanded_conv_6/depthwise', [(3, 3, 240, 1)]),\n",
       " ('expanded_conv_6/depthwise/BatchNorm', [(240,), (240,), (240,), (240,)]),\n",
       " ('expanded_conv_6/expand', [(1, 1, 40, 240)]),\n",
       " ('expanded_conv_6/expand/BatchNorm', [(240,), (240,), (240,), (240,)]),\n",
       " ('expanded_conv_6/project', [(1, 1, 240, 80)]),\n",
       " ('expanded_conv_6/project/BatchNorm', [(80,), (80,), (80,), (80,)]),\n",
       " ('expanded_conv_7/depthwise', [(3, 3, 200, 1)]),\n",
       " ('expanded_conv_7/depthwise/BatchNorm', [(200,), (200,), (200,), (200,)]),\n",
       " ('expanded_conv_7/expand', [(1, 1, 80, 200)]),\n",
       " ('expanded_conv_7/expand/BatchNorm', [(200,), (200,), (200,), (200,)]),\n",
       " ('expanded_conv_7/project', [(1, 1, 200, 80)]),\n",
       " ('expanded_conv_7/project/BatchNorm', [(80,), (80,), (80,), (80,)]),\n",
       " ('expanded_conv_8/depthwise', [(3, 3, 184, 1)]),\n",
       " ('expanded_conv_8/depthwise/BatchNorm', [(184,), (184,), (184,), (184,)]),\n",
       " ('expanded_conv_8/expand', [(1, 1, 80, 184)]),\n",
       " ('expanded_conv_8/expand/BatchNorm', [(184,), (184,), (184,), (184,)]),\n",
       " ('expanded_conv_8/project', [(1, 1, 184, 80)]),\n",
       " ('expanded_conv_8/project/BatchNorm', [(80,), (80,), (80,), (80,)]),\n",
       " ('expanded_conv_9/depthwise', [(3, 3, 184, 1)]),\n",
       " ('expanded_conv_9/depthwise/BatchNorm', [(184,), (184,), (184,), (184,)]),\n",
       " ('expanded_conv_9/expand', [(1, 1, 80, 184)]),\n",
       " ('expanded_conv_9/expand/BatchNorm', [(184,), (184,), (184,), (184,)]),\n",
       " ('expanded_conv_9/project', [(1, 1, 184, 80)]),\n",
       " ('expanded_conv_9/project/BatchNorm', [(80,), (80,), (80,), (80,)])]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(item[0], [iitem.shape for iitem in item[1]]) for item in order_keras_weights.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6430fd36",
   "metadata": {},
   "source": [
    "## Create MNV3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bc96a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "backbone = backbones.MobileNet(\n",
    "    model_id='MobileNetV3Large', filter_size_scale=1.0)\n",
    "\n",
    "num_classes = 1001\n",
    "model = classification_model.ClassificationModel(\n",
    "    backbone=backbone,\n",
    "    num_classes=num_classes,\n",
    "    dropout_rate=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "42a35dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classification_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "mobile_net (MobileNet)       {'2': (None, None, None,  4226432   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1001)              1282281   \n",
      "=================================================================\n",
      "Total params: 5,508,713\n",
      "Trainable params: 5,484,313\n",
      "Non-trainable params: 24,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "05eb4696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dense/kernel:0', TensorShape([1280, 1001])),\n",
       " ('dense/bias:0', TensorShape([1001]))]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(item.name, item.shape) for item in model.layers[4].weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d793a93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv2dbn_block',\n",
       " 'inverted_bottleneck_block',\n",
       " 'inverted_bottleneck_block_1',\n",
       " 'inverted_bottleneck_block_2',\n",
       " 'inverted_bottleneck_block_3',\n",
       " 'inverted_bottleneck_block_4',\n",
       " 'inverted_bottleneck_block_5',\n",
       " 'inverted_bottleneck_block_6',\n",
       " 'inverted_bottleneck_block_7',\n",
       " 'inverted_bottleneck_block_8',\n",
       " 'inverted_bottleneck_block_9',\n",
       " 'inverted_bottleneck_block_10',\n",
       " 'inverted_bottleneck_block_11',\n",
       " 'inverted_bottleneck_block_12',\n",
       " 'inverted_bottleneck_block_13',\n",
       " 'inverted_bottleneck_block_14',\n",
       " 'conv2dbn_block_1',\n",
       " 'conv2dbn_block_2']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[layer.name for layer in model.layers[1].layers if layer.weights]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bb7455",
   "metadata": {},
   "source": [
    "### Conv Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5595db7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv2dbn_block/conv2d/kernel:0',\n",
       " 'conv2dbn_block/batch_normalization/gamma:0',\n",
       " 'conv2dbn_block/batch_normalization/beta:0',\n",
       " 'conv2dbn_block/batch_normalization/moving_mean:0',\n",
       " 'conv2dbn_block/batch_normalization/moving_variance:0']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item.name for item in model.layers[1].layers[1].weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a8fb4a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv2dbn_block_2/conv2d/kernel:0', 'conv2dbn_block_2/conv2d/bias:0']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item.name for item in model.layers[1].layers[-2].weights]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d45ca5",
   "metadata": {},
   "source": [
    "### Inverted Bottleneck Layer without Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a57601a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inverted_bottleneck_block/depthwise_conv2d/depthwise_kernel:0',\n",
       " 'inverted_bottleneck_block/batch_normalization/gamma:0',\n",
       " 'inverted_bottleneck_block/batch_normalization/beta:0',\n",
       " 'inverted_bottleneck_block/conv2d/kernel:0',\n",
       " 'inverted_bottleneck_block/batch_normalization_1/gamma:0',\n",
       " 'inverted_bottleneck_block/batch_normalization_1/beta:0',\n",
       " 'inverted_bottleneck_block/batch_normalization/moving_mean:0',\n",
       " 'inverted_bottleneck_block/batch_normalization/moving_variance:0',\n",
       " 'inverted_bottleneck_block/batch_normalization_1/moving_mean:0',\n",
       " 'inverted_bottleneck_block/batch_normalization_1/moving_variance:0']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item.name for item in model.layers[1].layers[3].weights]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb89aefb",
   "metadata": {},
   "source": [
    "### Inverted Bottleneck Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7a5bd845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inverted_bottleneck_block_1/conv2d/kernel:0',\n",
       " 'inverted_bottleneck_block_1/batch_normalization/gamma:0',\n",
       " 'inverted_bottleneck_block_1/batch_normalization/beta:0',\n",
       " 'inverted_bottleneck_block_1/depthwise_conv2d/depthwise_kernel:0',\n",
       " 'inverted_bottleneck_block_1/batch_normalization_1/gamma:0',\n",
       " 'inverted_bottleneck_block_1/batch_normalization_1/beta:0',\n",
       " 'inverted_bottleneck_block_1/conv2d_1/kernel:0',\n",
       " 'inverted_bottleneck_block_1/batch_normalization_2/gamma:0',\n",
       " 'inverted_bottleneck_block_1/batch_normalization_2/beta:0',\n",
       " 'inverted_bottleneck_block_1/batch_normalization/moving_mean:0',\n",
       " 'inverted_bottleneck_block_1/batch_normalization/moving_variance:0',\n",
       " 'inverted_bottleneck_block_1/batch_normalization_1/moving_mean:0',\n",
       " 'inverted_bottleneck_block_1/batch_normalization_1/moving_variance:0',\n",
       " 'inverted_bottleneck_block_1/batch_normalization_2/moving_mean:0',\n",
       " 'inverted_bottleneck_block_1/batch_normalization_2/moving_variance:0']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item.name for item in model.layers[1].layers[5].weights]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea82a61",
   "metadata": {},
   "source": [
    "### Inverted Bottleneck Layer with SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4637f08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inverted_bottleneck_block_3/conv2d/kernel:0', TensorShape([1, 1, 24, 72])),\n",
       " ('inverted_bottleneck_block_3/batch_normalization/gamma:0',\n",
       "  TensorShape([72])),\n",
       " ('inverted_bottleneck_block_3/batch_normalization/beta:0', TensorShape([72])),\n",
       " ('inverted_bottleneck_block_3/depthwise_conv2d/depthwise_kernel:0',\n",
       "  TensorShape([5, 5, 72, 1])),\n",
       " ('inverted_bottleneck_block_3/batch_normalization_1/gamma:0',\n",
       "  TensorShape([72])),\n",
       " ('inverted_bottleneck_block_3/batch_normalization_1/beta:0',\n",
       "  TensorShape([72])),\n",
       " ('inverted_bottleneck_block_3/squeeze_excitation/conv2d_2/kernel:0',\n",
       "  TensorShape([1, 1, 72, 24])),\n",
       " ('inverted_bottleneck_block_3/squeeze_excitation/conv2d_2/bias:0',\n",
       "  TensorShape([24])),\n",
       " ('inverted_bottleneck_block_3/squeeze_excitation/conv2d_3/kernel:0',\n",
       "  TensorShape([1, 1, 24, 72])),\n",
       " ('inverted_bottleneck_block_3/squeeze_excitation/conv2d_3/bias:0',\n",
       "  TensorShape([72])),\n",
       " ('inverted_bottleneck_block_3/conv2d_1/kernel:0',\n",
       "  TensorShape([1, 1, 72, 40])),\n",
       " ('inverted_bottleneck_block_3/batch_normalization_2/gamma:0',\n",
       "  TensorShape([40])),\n",
       " ('inverted_bottleneck_block_3/batch_normalization_2/beta:0',\n",
       "  TensorShape([40])),\n",
       " ('inverted_bottleneck_block_3/batch_normalization/moving_mean:0',\n",
       "  TensorShape([72])),\n",
       " ('inverted_bottleneck_block_3/batch_normalization/moving_variance:0',\n",
       "  TensorShape([72])),\n",
       " ('inverted_bottleneck_block_3/batch_normalization_1/moving_mean:0',\n",
       "  TensorShape([72])),\n",
       " ('inverted_bottleneck_block_3/batch_normalization_1/moving_variance:0',\n",
       "  TensorShape([72])),\n",
       " ('inverted_bottleneck_block_3/batch_normalization_2/moving_mean:0',\n",
       "  TensorShape([40])),\n",
       " ('inverted_bottleneck_block_3/batch_normalization_2/moving_variance:0',\n",
       "  TensorShape([40]))]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(item.name, item.shape) for item in model.layers[1].layers[9].weights]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90281e12",
   "metadata": {},
   "source": [
    "## Convert checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "be9a5729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf2_to_tf1_name(tf2_layer_name):\n",
    "    '''\n",
    "    ['conv2dbn_block',\n",
    "     'inverted_bottleneck_block',\n",
    "     'inverted_bottleneck_block_1',\n",
    "     'inverted_bottleneck_block_2',\n",
    "     ......\n",
    "     'conv2dbn_block_1',\n",
    "     'conv2dbn_block_2']\n",
    "     \n",
    "     ['Conv',\n",
    "      'expanded_conv',\n",
    "      'expanded_conv_1',\n",
    "      'expanded_conv_2',\n",
    "      ......\n",
    "      'Conv_1',\n",
    "      'Conv_2'\n",
    "     ]\n",
    "    '''\n",
    "    if 'conv2dbn_block' in tf2_layer_name:\n",
    "        tf1_layer_name = tf2_layer_name.replace('conv2dbn_block', 'Conv')\n",
    "    elif 'inverted_bottleneck_block' in tf2_layer_name:\n",
    "        tf1_layer_name = tf2_layer_name.replace('inverted_bottleneck_block', 'expanded_conv')\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    return tf1_layer_name\n",
    "        \n",
    "def get_tf1_layers_by_tf2_name(tf2_layer_name, tf1_order_keras_weights):\n",
    "    tf1_layer_name = tf2_to_tf1_name(tf2_layer_name)\n",
    "    \n",
    "    tf1_layer_dict = {layer_name: tf1_order_keras_weights[layer_name] \n",
    "                      for layer_name in tf1_order_keras_weights \n",
    "                      if layer_name.split('/')[0] == tf1_layer_name}\n",
    "    \n",
    "    return tf1_layer_name, tf1_layer_dict\n",
    "\n",
    "\n",
    "def order_tf1_layer_weights(tf1_layer_dict, tf1_layer_name):\n",
    "    conv_order = ['expand', 'depthwise', 'squeeze_excite', 'project']\n",
    "    batch_norm_order = ['expand', 'depthwise', 'project']\n",
    "    \n",
    "    result_holder = []\n",
    "    \n",
    "    conv_holder = defaultdict(list)\n",
    "    batch_norm_holder = dict()\n",
    "    if tf1_layer_name.startswith('expanded_conv'):\n",
    "        for (layer_name, layer_weights) in sorted(tf1_layer_dict.items(), key=lambda x: x[0]):\n",
    "            layer_name_splits = layer_name.split('/')\n",
    "            component = layer_name_splits[1]\n",
    "                \n",
    "            if len(layer_name_splits) == 3 and layer_name_splits[2] == 'BatchNorm':\n",
    "                batch_norm_holder[component] = layer_weights\n",
    "            else:\n",
    "                conv_holder[component].extend(layer_weights)\n",
    "    \n",
    "        print([(name, len(conv_holder[name])) for name in conv_holder])\n",
    "        print([(name, len(conv_holder[name])) for name in batch_norm_holder])\n",
    "        for comp in conv_order:\n",
    "            if comp in conv_holder:\n",
    "                result_holder.extend(conv_holder[comp])\n",
    "            if comp in batch_norm_holder:\n",
    "                result_holder.extend(batch_norm_holder[comp][0:2])\n",
    "        for comp in batch_norm_order:\n",
    "            if comp in batch_norm_holder:\n",
    "                result_holder.extend(batch_norm_holder[comp][2:])\n",
    "    \n",
    "    elif tf1_layer_name.startswith('Conv'):\n",
    "        for (layer_name, layer_weights) in sorted(tf1_layer_dict.items(), key=lambda x: x[0]):\n",
    "            result_holder.extend(layer_weights)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    return result_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3750b44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Conv_2']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1_layer_name, tf1_layer_dict = get_tf1_layers_by_tf2_name('conv2dbn_block_2', order_keras_weights)\n",
    "sorted(list(tf1_layer_dict.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f4212813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(order_tf1_layer_weights(tf1_layer_dict, tf1_layer_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76580363",
   "metadata": {},
   "source": [
    "## Set weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ce9503fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2dbn_block\n",
      "inverted_bottleneck_block\n",
      "[('depthwise', 1), ('project', 1)]\n",
      "[('depthwise', 1), ('project', 1)]\n",
      "inverted_bottleneck_block_1\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1)]\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1)]\n",
      "inverted_bottleneck_block_2\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1)]\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1)]\n",
      "inverted_bottleneck_block_3\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1), ('squeeze_excite', 4)]\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1)]\n",
      "inverted_bottleneck_block_4\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1), ('squeeze_excite', 4)]\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1)]\n",
      "inverted_bottleneck_block_5\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1), ('squeeze_excite', 4)]\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1)]\n",
      "inverted_bottleneck_block_6\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1)]\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1)]\n",
      "inverted_bottleneck_block_7\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1)]\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1)]\n",
      "inverted_bottleneck_block_8\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1)]\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1)]\n",
      "inverted_bottleneck_block_9\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1)]\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1)]\n",
      "inverted_bottleneck_block_10\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1), ('squeeze_excite', 4)]\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1)]\n",
      "inverted_bottleneck_block_11\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1), ('squeeze_excite', 4)]\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1)]\n",
      "inverted_bottleneck_block_12\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1), ('squeeze_excite', 4)]\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1)]\n",
      "inverted_bottleneck_block_13\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1), ('squeeze_excite', 4)]\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1)]\n",
      "inverted_bottleneck_block_14\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1), ('squeeze_excite', 4)]\n",
      "[('depthwise', 1), ('expand', 1), ('project', 1)]\n",
      "conv2dbn_block_1\n",
      "conv2dbn_block_2\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[1].layers:\n",
    "    if layer.weights:\n",
    "        layer_name = layer.name\n",
    "        print(layer_name)\n",
    "        tf1_layer_name, tf1_layer_dict = get_tf1_layers_by_tf2_name(layer_name, order_keras_weights)\n",
    "        tf1_weights = order_tf1_layer_weights(tf1_layer_dict, tf1_layer_name)\n",
    "        layer.set_weights(tf1_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d7a34fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_kernel, head_bias = order_keras_weights['Logits/Conv2d_1c_1x1']\n",
    "head_kernel = np.squeeze(head_kernel)\n",
    "(head_kernel.shape, head_bias.shape)\n",
    "\n",
    "model.layers[4].set_weights([head_kernel, head_bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "06c732c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classification_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "mobile_net (MobileNet)       {'2': (None, None, None,  4226432   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1001)              1282281   \n",
      "=================================================================\n",
      "Total params: 5,508,713\n",
      "Trainable params: 5,484,313\n",
      "Non-trainable params: 24,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bb2c0e",
   "metadata": {},
   "source": [
    "## Launch evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c845f500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageNetConfig(name='imagenet2012', data_dir='gs://tf_mobilenet/imagenet/imagenet-2012-tfrecord', filenames=None, builder='records', split='validation', image_size=224, num_classes=1000, num_channels=3, num_examples=1281167, batch_size=128, use_per_replica_batch_size=True, num_devices=1, dtype='float32', one_hot=False, augmenter=AugmentConfig(name='autoaugment', params=None), download=False, shuffle_buffer_size=10000, file_shuffle_buffer_size=100, skip_decoding=True, cache=False, tf_data_service=None, mean_subtract=True, standardize=True, num_eval_examples=50000)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from research.mobilenet import mobilenet_trainer\n",
    "\n",
    "d_config = mobilenet_trainer._get_dataset_config().get('imagenet2012')()\n",
    "# build evaluation dataset\n",
    "d_config.split = 'validation'\n",
    "d_config.batch_size = 128\n",
    "d_config.one_hot = False\n",
    "d_config.data_dir = 'gs://tf_mobilenet/imagenet/imagenet-2012-tfrecord'\n",
    "\n",
    "d_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9f2f0801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 33s 79ms/step - loss: 5.5589 - sparse_categorical_accuracy: 0.7536\n"
     ]
    }
   ],
   "source": [
    "# the checkpoint is trained using slim\n",
    "eval_dataset = mobilenet_trainer.get_dataset(d_config, slim_preprocess=True)\n",
    "\n",
    "# compile model\n",
    "if d_config.one_hot:\n",
    "    loss_obj = tf.keras.losses.CategoricalCrossentropy()\n",
    "else:\n",
    "    loss_obj = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss=loss_obj,\n",
    "    metrics=[mobilenet_trainer._get_metrics(one_hot=d_config.one_hot)['acc']])\n",
    "\n",
    "# run evaluation\n",
    "eval_result = model.evaluate(eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef32fe1",
   "metadata": {},
   "source": [
    "## Save checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d3769107",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_format = 'ckpt'\n",
    "save_path = '/home/jupyter/mobilenet_v3large_1.0'\n",
    "\n",
    "checkpoint_items = model.checkpoint_items\n",
    "\n",
    "if save_format == 'ckpt':\n",
    "    checkpoint = tf.train.Checkpoint(model=model, **checkpoint_items)\n",
    "    manager = tf.train.CheckpointManager(checkpoint,\n",
    "                                         directory=save_path,\n",
    "                                         max_to_keep=3)\n",
    "    manager.save()\n",
    "else:\n",
    "    model.save(save_path, save_format=save_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7407420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m71"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
