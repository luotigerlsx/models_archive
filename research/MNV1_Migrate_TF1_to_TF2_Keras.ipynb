{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Convert TF v1 MobilenetV1 to TF v2 Keras.\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import Text, List, Dict, Tuple, Callable\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Tensor: shape=(), dtype=int32, numpy=1>,\n <tf.Tensor: shape=(), dtype=int32, numpy=2>,\n <tf.Tensor: shape=(), dtype=int32, numpy=3>]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.io.decode_csv('1,2,3', record_defaults=[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from research.mobilenet.mobilenet_v1 import mobilenet_v1\n",
    "from research.mobilenet.configs import archs\n",
    "from research.mobilenet.mobilenet_trainer import _get_dataset_config, get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" || exit\n",
    "DIR=\"$( pwd )\"\n",
    "SRC_DIR=${DIR}\"/../../../\"\n",
    "export PYTHONPATH=${PYTHONPATH}:${SRC_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_checkpoint = '/Users/luoshixin/Downloads/mobilenet_checkpoints/mobilenet_v1_1.0_224/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck = tf.train.latest_checkpoint(source_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list_variables() missing 1 required positional argument: 'ckpt_dir_or_file'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-fb833721338f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlist_variables\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: list_variables() missing 1 required positional argument: 'ckpt_dir_or_file'"
     ]
    }
   ],
   "source": [
    "tf.train.list_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import Text, List, Dict, Tuple, Callable\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def _process_moving_average(ma_terms: List[Text]) -> List[Text]:\n",
    "  \"\"\"\n",
    "    MobilenetV2/Conv/BatchNorm/moving_variance\n",
    "    MobilenetV2/Conv/BatchNorm/moving_variance/ExponentialMovingAverage\n",
    "    MobilenetV3/expanded_conv_9/project/BatchNorm/moving_mean/ExponentialMovingAverage\n",
    "  Args:\n",
    "    ma_terms: a list of names related to moving average\n",
    "\n",
    "  Returns:\n",
    "    a list of names after de-duplicating\n",
    "  \"\"\"\n",
    "\n",
    "  dedup_holder = dict()\n",
    "  for item in ma_terms:\n",
    "    base_name = item\n",
    "    item_split = item.split('/')\n",
    "    if 'moving_' in item_split[-2]:\n",
    "      base_name = '/'.join(item_split[0:-1])\n",
    "\n",
    "    if ((base_name not in dedup_holder)\n",
    "        or (len(item) > len(dedup_holder[base_name]))):\n",
    "      dedup_holder[base_name] = item\n",
    "\n",
    "  return list(dedup_holder.values())\n",
    "\n",
    "\n",
    "def _load_weights_from_ckpt(checkpoint_path: Text,\n",
    "                            include_filters: List[Text],\n",
    "                            exclude_filters: List[Text]\n",
    "                            ) -> Dict[Text, tf.Tensor]:\n",
    "  \"\"\"Load all the weights stored in the checkpoint as {var_name: var_value}\n",
    "\n",
    "  Args:\n",
    "    checkpoint_path: path to the checkpoint file xxxxx.ckpt\n",
    "    include_filters: list of keywords that determine which var_names should be\n",
    "    kept in the output list\n",
    "    exclude_filters: list of keywords that determine which var_names should be\n",
    "    excluded from the output list\n",
    "\n",
    "  Returns:\n",
    "    A dictionary of {var_name: tensor values}\n",
    "  \"\"\"\n",
    "  reader = tf.compat.v1.train.NewCheckpointReader(checkpoint_path)\n",
    "  var_shape_map = reader.get_variable_to_shape_map()\n",
    "  ma_terms = list()\n",
    "\n",
    "  var_value_map = {}\n",
    "  for item in var_shape_map:\n",
    "    include_check = True\n",
    "    if include_filters:\n",
    "      include_check = any([to_check in item\n",
    "                           for to_check in include_filters])\n",
    "    exclude_check = True\n",
    "    if exclude_filters:\n",
    "      exclude_check = all([to_check not in item\n",
    "                           for to_check in exclude_filters])\n",
    "\n",
    "    if exclude_check and 'moving_' in item:\n",
    "      ma_terms.append(item)\n",
    "    elif exclude_check and include_check:\n",
    "      var_value_map[item] = reader.get_tensor(item)\n",
    "\n",
    "  processed_ma_terms = _process_moving_average(ma_terms)\n",
    "  for p_item in processed_ma_terms:\n",
    "    var_value_map[p_item] = reader.get_tensor(p_item)\n",
    "\n",
    "  return var_value_map\n",
    "\n",
    "\n",
    "def _decouple_layer_name(var_value_map: Dict[Text, tf.Tensor],\n",
    "                         use_mv_average: bool = True\n",
    "                         ) -> List[Tuple[Text, Text, tf.Tensor]]:\n",
    "  \"\"\"Sort the names of the weights by the layer they correspond to. The example\n",
    "  names of the weightes:\n",
    "    MobilenetV1/Conv2d_0/weights\n",
    "    MobilenetV1/Conv2d_9_pointwise/weights\n",
    "    MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta\n",
    "    MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta/ExponentialMovingAverage\n",
    "    MobilenetV2/expanded_conv_9/project/weights/ExponentialMovingAverage\n",
    "    MobilenetV2/expanded_conv_9/project/BatchNorm/beta/ExponentialMovingAverage\n",
    "    Model_Name/Layer_Name/Component_Name[/Extra]\n",
    "\n",
    "  Args:\n",
    "    var_value_map: a dictionary of {var_name: tensor values}\n",
    "    use_mv_average: whether `ExponentialMovingAverage` should be used. If this\n",
    "    is true, the `ExponentialMovingAverage` related weightes should be included\n",
    "    in  `var_value_map`.\n",
    "\n",
    "  Returns:\n",
    "    A list of (layer_num, layer_name, layer_component, weight_value)\n",
    "  \"\"\"\n",
    "  layer_list = []\n",
    "  for weight_name, weight_value in var_value_map.items():\n",
    "    weight_name_split = weight_name.split('/')\n",
    "    if use_mv_average and 'ExponentialMovingAverage' in weight_name:\n",
    "      # MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta/ExponentialMovingAverage\n",
    "      layer_name = '/'.join(weight_name_split[1:-2])\n",
    "      layer_component = '/'.join(weight_name_split[-2:-1])\n",
    "    else:\n",
    "      # MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta\n",
    "      layer_name = '/'.join(weight_name_split[1:-1])\n",
    "      layer_component = '/'.join(weight_name_split[-1:])\n",
    "\n",
    "    layer_list.append(\n",
    "      (layer_name, layer_component, weight_value))\n",
    "\n",
    "  return layer_list\n",
    "\n",
    "\n",
    "def _layer_weights_list_to_map(\n",
    "    layer_ordered_list: List[Tuple[Text, Text, tf.Tensor]]\n",
    ") -> Dict[Text, List[tf.Tensor]]:\n",
    "  \"\"\"Organize same layer with multiple components into group.\n",
    "  For example: BatchNorm has 'gamma', 'beta', 'moving_mean', 'moving_variance'\n",
    "\n",
    "  Args:\n",
    "    layer_ordered_list: A list of (layer_num, layer_name,\n",
    "    layer_component, weight_value)\n",
    "\n",
    "  Returns:\n",
    "    A dictionary of {layer_name: layer_weights}\n",
    "  \"\"\"\n",
    "\n",
    "  # define the vars order in Keras layer\n",
    "  batchnorm_order = ['gamma', 'beta', 'moving_mean', 'moving_variance']\n",
    "  dense_cnn_order = ['weights', 'biases']\n",
    "  depthwise_order = ['depthwise_weights', 'biases']\n",
    "\n",
    "  # Organize same layer with multiple components into group\n",
    "  keras_weights = defaultdict(list)\n",
    "\n",
    "  for (layer_name, layer_component, weight) in layer_ordered_list:\n",
    "    keras_weights[layer_name].append((layer_component, weight))\n",
    "\n",
    "  # Sort within each group. The ordering should be\n",
    "  ordered_layer_weights = {}\n",
    "\n",
    "  for group_name, group in keras_weights.items():\n",
    "    # format of group: [(layer_component, weight)]\n",
    "    if len(group) == 1:\n",
    "      order_weight_group = [group[0][1]]\n",
    "    else:\n",
    "      group_len = len(group)\n",
    "      order_weight_group = [0] * group_len\n",
    "\n",
    "      if group_len == 2:\n",
    "        target_order = dense_cnn_order\n",
    "        if 'depthwise' in group_name:\n",
    "          target_order = depthwise_order\n",
    "      elif group_len == 4:\n",
    "        target_order = batchnorm_order\n",
    "      else:\n",
    "        raise ValueError(\n",
    "          'The number of components {} in a layer is not supported'.format(\n",
    "            group_len))\n",
    "\n",
    "      for item_name, item_value in group:\n",
    "        index = target_order.index(item_name)\n",
    "        order_weight_group[index] = item_value\n",
    "\n",
    "    ordered_layer_weights[group_name] = order_weight_group\n",
    "\n",
    "  return ordered_layer_weights\n",
    "\n",
    "\n",
    "def generate_layer_weights_map(checkpoint_path: Text,\n",
    "                               include_filters: List[Text],\n",
    "                               exclude_filters: List[Text],\n",
    "                               use_mv_average: bool = True\n",
    "                               ) -> Dict[Text, List[tf.Tensor]]:\n",
    "  \"\"\"Generate a dictionary of {layer_name: layer_weights} from checkpoint.\n",
    "\n",
    "  Args:\n",
    "    checkpoint_path: path to the checkpoint file xxxxx.ckpt\n",
    "    include_filters: list of keywords that determine which var_names should be\n",
    "    kept in the output list\n",
    "    exclude_filters: list of keywords that determine which var_names should be\n",
    "    excluded from the output list\n",
    "    use_mv_average: whether `ExponentialMovingAverage` should be used. If this\n",
    "    is true, the `ExponentialMovingAverage` related weightes should be included\n",
    "    in  `var_value_map`.\n",
    "\n",
    "  Returns:\n",
    "    A dictionary of {layer_name: layer_weights}\n",
    "  \"\"\"\n",
    "  var_value_map = _load_weights_from_ckpt(\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    include_filters=include_filters,\n",
    "    exclude_filters=exclude_filters)\n",
    "\n",
    "  layer_ordered_list = _decouple_layer_name(\n",
    "    var_value_map=var_value_map,\n",
    "    use_mv_average=use_mv_average)\n",
    "\n",
    "  ordered_layer_weights = _layer_weights_list_to_map(\n",
    "    layer_ordered_list=layer_ordered_list)\n",
    "\n",
    "  return ordered_layer_weights\n",
    "\n",
    "\n",
    "def load_tf2_keras_model_weights(keras_model: tf.keras.Model,\n",
    "                                 weights_map: Dict[Text, List[tf.Tensor]],\n",
    "                                 name_map_fn: Callable\n",
    "                                 ):\n",
    "  \"\"\"Load a TF2 Keras model with a {layer_name: layer_weights} dictionary\n",
    "  generated from TF1 checkpoint.\n",
    "\n",
    "  Args:\n",
    "    keras_model: TF2 Keras model\n",
    "    weights_map: a dictionary of {layer_name: layer_weights}\n",
    "    name_map_fn: a function that convert TF2 layer name to TF1 layer name\n",
    "\n",
    "  Returns:\n",
    "\n",
    "  \"\"\"\n",
    "  trainable_layer_types = (\n",
    "    tf.keras.layers.Conv2D,\n",
    "    tf.keras.layers.BatchNormalization,\n",
    "    tf.keras.layers.Dense,\n",
    "    tf.keras.layers.DepthwiseConv2D,\n",
    "  )\n",
    "\n",
    "  trainable_layers = [layer for layer in keras_model.layers\n",
    "                      if isinstance(layer, trainable_layer_types)]\n",
    "\n",
    "  for layer in trainable_layers:\n",
    "    name = layer.name\n",
    "    tf1_name = name_map_fn(name)\n",
    "    weight = weights_map[tf1_name]\n",
    "    layer.set_weights(weight)\n",
    "\n",
    "\n",
    "def save_keras_checkpoint(keras_model: tf.keras.Model,\n",
    "                          save_path: Text,\n",
    "                          save_format: Text = 'ckpt'\n",
    "                          ):\n",
    "  \"\"\"Save a TF2 Keras model to a checkpoint.\n",
    "\n",
    "  Args:\n",
    "    keras_model: TF2 Keras model\n",
    "    save_format: save format: ckpt and tf\n",
    "    save_path: path to save the checkpoint\n",
    "\n",
    "  Returns:\n",
    "\n",
    "  \"\"\"\n",
    "  if save_format == 'ckpt':\n",
    "    checkpoint = tf.train.Checkpoint(model=keras_model)\n",
    "    manager = tf.train.CheckpointManager(checkpoint,\n",
    "                                         directory=save_path,\n",
    "                                         max_to_keep=1)\n",
    "    manager.save()\n",
    "  else:\n",
    "    keras_model.save(save_path, save_format=save_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_value_map = _load_weights_from_ckpt(source_checkpoint, \n",
    "                                 ['ExponentialMovingAverage'], \n",
    "                                 ['RMSProp', 'global_step', 'loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_ordered_list = _decouple_layer_name(var_value_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_keras_weights = _layer_weights_list_to_map(layer_ordered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Conv2d_0', [(3, 3, 3, 24)]),\n",
       " ('Conv2d_0/BatchNorm', [(24,), (24,), (24,), (24,)]),\n",
       " ('Conv2d_10_depthwise', [(3, 3, 384, 1)]),\n",
       " ('Conv2d_10_depthwise/BatchNorm', [(384,), (384,), (384,), (384,)]),\n",
       " ('Conv2d_10_pointwise', [(1, 1, 384, 384)]),\n",
       " ('Conv2d_10_pointwise/BatchNorm', [(384,), (384,), (384,), (384,)]),\n",
       " ('Conv2d_11_depthwise', [(3, 3, 384, 1)]),\n",
       " ('Conv2d_11_depthwise/BatchNorm', [(384,), (384,), (384,), (384,)]),\n",
       " ('Conv2d_11_pointwise', [(1, 1, 384, 384)]),\n",
       " ('Conv2d_11_pointwise/BatchNorm', [(384,), (384,), (384,), (384,)]),\n",
       " ('Conv2d_12_depthwise', [(3, 3, 384, 1)]),\n",
       " ('Conv2d_12_depthwise/BatchNorm', [(384,), (384,), (384,), (384,)]),\n",
       " ('Conv2d_12_pointwise', [(1, 1, 384, 768)]),\n",
       " ('Conv2d_12_pointwise/BatchNorm', [(768,), (768,), (768,), (768,)]),\n",
       " ('Conv2d_13_depthwise', [(3, 3, 768, 1)]),\n",
       " ('Conv2d_13_depthwise/BatchNorm', [(768,), (768,), (768,), (768,)]),\n",
       " ('Conv2d_13_pointwise', [(1, 1, 768, 768)]),\n",
       " ('Conv2d_13_pointwise/BatchNorm', [(768,), (768,), (768,), (768,)]),\n",
       " ('Conv2d_1_depthwise', [(3, 3, 24, 1)]),\n",
       " ('Conv2d_1_depthwise/BatchNorm', [(24,), (24,), (24,), (24,)]),\n",
       " ('Conv2d_1_pointwise', [(1, 1, 24, 48)]),\n",
       " ('Conv2d_1_pointwise/BatchNorm', [(48,), (48,), (48,), (48,)]),\n",
       " ('Conv2d_2_depthwise', [(3, 3, 48, 1)]),\n",
       " ('Conv2d_2_depthwise/BatchNorm', [(48,), (48,), (48,), (48,)]),\n",
       " ('Conv2d_2_pointwise', [(1, 1, 48, 96)]),\n",
       " ('Conv2d_2_pointwise/BatchNorm', [(96,), (96,), (96,), (96,)]),\n",
       " ('Conv2d_3_depthwise', [(3, 3, 96, 1)]),\n",
       " ('Conv2d_3_depthwise/BatchNorm', [(96,), (96,), (96,), (96,)]),\n",
       " ('Conv2d_3_pointwise', [(1, 1, 96, 96)]),\n",
       " ('Conv2d_3_pointwise/BatchNorm', [(96,), (96,), (96,), (96,)]),\n",
       " ('Conv2d_4_depthwise', [(3, 3, 96, 1)]),\n",
       " ('Conv2d_4_depthwise/BatchNorm', [(96,), (96,), (96,), (96,)]),\n",
       " ('Conv2d_4_pointwise', [(1, 1, 96, 192)]),\n",
       " ('Conv2d_4_pointwise/BatchNorm', [(192,), (192,), (192,), (192,)]),\n",
       " ('Conv2d_5_depthwise', [(3, 3, 192, 1)]),\n",
       " ('Conv2d_5_depthwise/BatchNorm', [(192,), (192,), (192,), (192,)]),\n",
       " ('Conv2d_5_pointwise', [(1, 1, 192, 192)]),\n",
       " ('Conv2d_5_pointwise/BatchNorm', [(192,), (192,), (192,), (192,)]),\n",
       " ('Conv2d_6_depthwise', [(3, 3, 192, 1)]),\n",
       " ('Conv2d_6_depthwise/BatchNorm', [(192,), (192,), (192,), (192,)]),\n",
       " ('Conv2d_6_pointwise', [(1, 1, 192, 384)]),\n",
       " ('Conv2d_6_pointwise/BatchNorm', [(384,), (384,), (384,), (384,)]),\n",
       " ('Conv2d_7_depthwise', [(3, 3, 384, 1)]),\n",
       " ('Conv2d_7_depthwise/BatchNorm', [(384,), (384,), (384,), (384,)]),\n",
       " ('Conv2d_7_pointwise', [(1, 1, 384, 384)]),\n",
       " ('Conv2d_7_pointwise/BatchNorm', [(384,), (384,), (384,), (384,)]),\n",
       " ('Conv2d_8_depthwise', [(3, 3, 384, 1)]),\n",
       " ('Conv2d_8_depthwise/BatchNorm', [(384,), (384,), (384,), (384,)]),\n",
       " ('Conv2d_8_pointwise', [(1, 1, 384, 384)]),\n",
       " ('Conv2d_8_pointwise/BatchNorm', [(384,), (384,), (384,), (384,)]),\n",
       " ('Conv2d_9_depthwise', [(3, 3, 384, 1)]),\n",
       " ('Conv2d_9_depthwise/BatchNorm', [(384,), (384,), (384,), (384,)]),\n",
       " ('Conv2d_9_pointwise', [(1, 1, 384, 384)]),\n",
       " ('Conv2d_9_pointwise/BatchNorm', [(384,), (384,), (384,), (384,)]),\n",
       " ('Logits/Conv2d_1c_1x1', [(1, 1, 768, 1001), (1001,)])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(item[0], [iitem.shape for iitem in item[1]]) for item in order_keras_weights.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobinetv1_tf1_tf2_name_convert(tf2_layer_name: Text) -> Text:\n",
    "  \"\"\"Convert TF2 layer name to TF1 layer name. Examples:\n",
    "  Conv2d_0/batch_norm -> Conv2d_0/BatchNorm\n",
    "  Conv2d_4/pointwise/batch_norm -> Conv2d_4_pointwise/BatchNorm\n",
    "  top/Conv2d_1x1_output -> Logits/Conv2d_1c_1x1\n",
    "\n",
    "  Args:\n",
    "    tf2_layer_name: name of TF2 layer\n",
    "\n",
    "  Returns:\n",
    "    name of TF1 layer\n",
    "  \"\"\"\n",
    "  if 'top/Conv2d_1x1_output' in tf2_layer_name:\n",
    "    tf1_layer_name = 'Logits/Conv2d_1c_1x1'\n",
    "  else:\n",
    "    if 'batch_norm' in tf2_layer_name:\n",
    "      tf2_layer_name = tf2_layer_name.replace('batch_norm', 'BatchNorm')\n",
    "\n",
    "    if '/pointwise' in tf2_layer_name:\n",
    "      tf1_layer_name = tf2_layer_name.replace('/pointwise', '_pointwise')\n",
    "    elif '/depthwise' in tf2_layer_name:\n",
    "      tf1_layer_name = tf2_layer_name.replace('/depthwise', '_depthwise')\n",
    "    else:\n",
    "      tf1_layer_name = tf2_layer_name\n",
    "\n",
    "  return tf1_layer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MobileNetV1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "Conv2d_0_0 (Conv2D)          (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "Conv2d_0_0/batch_norm (Batch (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "Conv2d_0_0/relu6 (Activation (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "Conv2d_1/depthwise (Depthwis (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "Conv2d_1/depthwise/batch_nor (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "Conv2d_1/depthwise/relu6 (Ac (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "Conv2d_1/pointwise (Conv2D)  (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "Conv2d_1/pointwise/batch_nor (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "Conv2d_1/pointwise/relu6 (Ac (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "Conv2d_2/depthwise (Depthwis (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "Conv2d_2/depthwise/batch_nor (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "Conv2d_2/depthwise/relu6 (Ac (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv2d_2/pointwise (Conv2D)  (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "Conv2d_2/pointwise/batch_nor (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "Conv2d_2/pointwise/relu6 (Ac (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv2d_3/depthwise (Depthwis (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "Conv2d_3/depthwise/batch_nor (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "Conv2d_3/depthwise/relu6 (Ac (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv2d_3/pointwise (Conv2D)  (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "Conv2d_3/pointwise/batch_nor (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "Conv2d_3/pointwise/relu6 (Ac (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv2d_4/depthwise (Depthwis (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "Conv2d_4/depthwise/batch_nor (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "Conv2d_4/depthwise/relu6 (Ac (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv2d_4/pointwise (Conv2D)  (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "Conv2d_4/pointwise/batch_nor (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Conv2d_4/pointwise/relu6 (Ac (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "Conv2d_5/depthwise (Depthwis (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "Conv2d_5/depthwise/batch_nor (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Conv2d_5/depthwise/relu6 (Ac (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "Conv2d_5/pointwise (Conv2D)  (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "Conv2d_5/pointwise/batch_nor (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Conv2d_5/pointwise/relu6 (Ac (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "Conv2d_6/depthwise (Depthwis (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "Conv2d_6/depthwise/batch_nor (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Conv2d_6/depthwise/relu6 (Ac (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "Conv2d_6/pointwise (Conv2D)  (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "Conv2d_6/pointwise/batch_nor (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv2d_6/pointwise/relu6 (Ac (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "Conv2d_7/depthwise (Depthwis (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "Conv2d_7/depthwise/batch_nor (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv2d_7/depthwise/relu6 (Ac (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "Conv2d_7/pointwise (Conv2D)  (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "Conv2d_7/pointwise/batch_nor (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv2d_7/pointwise/relu6 (Ac (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "Conv2d_8/depthwise (Depthwis (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "Conv2d_8/depthwise/batch_nor (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv2d_8/depthwise/relu6 (Ac (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "Conv2d_8/pointwise (Conv2D)  (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "Conv2d_8/pointwise/batch_nor (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv2d_8/pointwise/relu6 (Ac (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "Conv2d_9/depthwise (Depthwis (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "Conv2d_9/depthwise/batch_nor (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv2d_9/depthwise/relu6 (Ac (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "Conv2d_9/pointwise (Conv2D)  (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "Conv2d_9/pointwise/batch_nor (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv2d_9/pointwise/relu6 (Ac (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "Conv2d_10/depthwise (Depthwi (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "Conv2d_10/depthwise/batch_no (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv2d_10/depthwise/relu6 (A (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "Conv2d_10/pointwise (Conv2D) (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "Conv2d_10/pointwise/batch_no (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv2d_10/pointwise/relu6 (A (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "Conv2d_11/depthwise (Depthwi (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "Conv2d_11/depthwise/batch_no (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv2d_11/depthwise/relu6 (A (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "Conv2d_11/pointwise (Conv2D) (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "Conv2d_11/pointwise/batch_no (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv2d_11/pointwise/relu6 (A (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "Conv2d_12/depthwise (Depthwi (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "Conv2d_12/depthwise/batch_no (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "Conv2d_12/depthwise/relu6 (A (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "Conv2d_12/pointwise (Conv2D) (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "Conv2d_12/pointwise/batch_no (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "Conv2d_12/pointwise/relu6 (A (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "Conv2d_13/depthwise (Depthwi (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "Conv2d_13/depthwise/batch_no (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "Conv2d_13/depthwise/relu6 (A (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "Conv2d_13/pointwise (Conv2D) (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "Conv2d_13/pointwise/batch_no (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "Conv2d_13/pointwise/relu6 (A (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "top/GlobalPool (GlobalAverag (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "top/Reshape (Reshape)        (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "top/Dropout (Dropout)        (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "top/Conv2d_1x1_output (Conv2 (None, 1, 1, 1001)        1026025   \n",
      "_________________________________________________________________\n",
      "top/SpatialSqueeze (Reshape) (None, 1001)              0         \n",
      "_________________________________________________________________\n",
      "top/Predictions (Activation) (None, 1001)              0         \n",
      "=================================================================\n",
      "Total params: 4,254,889\n",
      "Trainable params: 4,233,001\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "config = archs.MobileNetV1Config()\n",
    "config.width_multiplier = 1.0\n",
    "model = mobilenet_v1(config=config)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_tf2_keras_model_weights(model, order_keras_weights, mobinetv1_tf1_tf2_name_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    metrics=[tf.keras.metrics.categorical_crossentropy])\n",
    "\n",
    "save_format = 'ckpt'\n",
    "save_path = '/Users/luoshixin/Downloads/mobilenet_v1_ck'\n",
    "\n",
    "if save_format == 'ckpt':\n",
    "    checkpoint = tf.train.Checkpoint(model=model)\n",
    "    manager = tf.train.CheckpointManager(checkpoint,\n",
    "                                         directory=save_path,\n",
    "                                         max_to_keep=1)\n",
    "    manager.save()\n",
    "else:\n",
    "    model.save(save_path, save_format=save_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_config = _get_dataset_config().get(\"imagenette\")()\n",
    "d_config.split = 'validation'\n",
    "eval_dataset = get_dataset(d_config)\n",
    "for batch in eval_dataset.take(1):\n",
    "    data, label = batch[0], batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.4249034e-09, 5.1374682e-09, 1.3301625e-09, ..., 5.1343602e-10,\n",
       "        5.2039693e-09, 8.2226943e-06],\n",
       "       [1.3226485e-11, 2.8857193e-11, 2.6858283e-11, ..., 2.2072804e-11,\n",
       "        6.1748051e-09, 4.1291774e-09],\n",
       "       [1.6818857e-09, 7.9699576e-01, 5.4981319e-06, ..., 2.1244281e-04,\n",
       "        1.1076544e-05, 6.3732131e-08],\n",
       "       ...,\n",
       "       [3.2478045e-08, 5.9373335e-08, 1.2961380e-07, ..., 2.5657037e-08,\n",
       "        1.0997113e-06, 6.1789278e-06],\n",
       "       [1.4707939e-07, 5.6232446e-05, 3.6148110e-06, ..., 1.9385812e-08,\n",
       "        2.1747068e-04, 8.2438401e-06],\n",
       "       [9.8925716e-07, 1.5429567e-05, 3.1129814e-05, ..., 8.9486957e-06,\n",
       "        5.9194866e-05, 2.1502106e-05]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}